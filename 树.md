# 树
在图论中，树(Tree）是一种无向图（undirected graph），其中任意两个顶点间存在唯一一条路径. 即只要没有回路的连通图就是树.

树的高度: 根节点的高度
节点的高度: 节点到叶子节点的**最长路径**(边数)
节点的深度: **根节点**到这个节点所经历的边的个数
节点的层数: 节点的深度+1

> 高度 : 从下往上度量; 深度 : 从上往下度量.

## 二叉树
每个节点至多有两个“叉”， 也就是两个子节点， 分别是左子节点和右子节点.

叶子节点全都在最底层， 且除了叶子节点之外， 每个节点都有左右两个子节点， 这种二叉树就叫作**满二叉树**.
叶子节点都在最底下两层， 最后一层的叶子节点都靠左排列， 并且除了最后一层， 其他层的节点个数都要达到最大， 这种二叉树叫作**完全二叉树**. 完全二叉树有一个很好的性质：父结点和子节点的序号有着对应关系: 当根节点的值为 1 的情况下，若父结点的序号是 i，那么左子节点的序号就是 2i，右子节点的序号是 2i+1. 这个性质使得完全二叉树利用数组存储时可以极大地节省空间，以及利用序号找到某个节点的父结点和子节点.

## 平衡二叉树
平衡二叉树 是一棵二叉排序树，且具有以下性质：
1. 可以是一棵空树
2. 如果不是空树，它的左右两个子树的高度差的绝对值不超过 1，并且左右两个子树都是一棵平衡二叉树.

平衡二叉树的常用实现方法有 红黑树、AVL 树、替罪羊树、加权平衡树、伸展树 等.

### 存储方式
#### 基于指针的链式存储法
每个节点有三个字段， 其中一个存储数据， 另外两个是指向左右子节点的指针．

#### 基于数组的顺序存储法
如果节点 X 存储在数组中下标为 i 的位置， 下标为 2 * i 的位置存储的就是左子节点， 下标为 2 * i + 1 的位置存储的就是右子节点． 反过来， 下标为 i/2 的位置存储就是它的父节点．通过这种方式， 我们只要知道根节点存储的位置（**一般情况下， 为了方便计算子节点， 根节点会存储在下标为 1 的位置**）．

一棵完全二叉树， 所以仅仅“浪费”了一个下标为 0 的存储位置. 如果是非完全二叉树， 其实会浪费比较多的数组存储空间.
>　堆其实就是一种完全二叉树， 最常用的存储方式就是数组

### 遍历
- 前序遍历(Pre-Order,根->左->右): 对于树中的任意节点来说， 先打印这个节点， 然后再打印它的左子树， 最后打印它的右子树

  ```go
  preOrder(root *TreeNode){
		if(root == nil){
			return
		}

		fmt.Println(root.data)
		preOrder(root.left)
		preOrder(root.right)
  }
  ```
- 中序遍历(In-Order,左->根->右): 对于树中的任意节点来说， 先打印它的左子树， 然后再打印它本身， 最后打印它的右子树

  ```go
  inOrder(root *TreeNode){
		if(root == nil){
			return
		}

		inOrder(root.left)
		fmt.Println(root.data)
		inOrder(root.right)
  }
- 后序遍历(Post-Order,左->右->根): 对于树中的任意节点来说， 先打印它的左子树， 然后再打印它的右子树， 最后打印这个节点本身

  ```go
  postOrder(root *TreeNode){
		if(root == nil){
			return
		}

		postOrder(root.left)
		postOrder(root.right)
		fmt.Println(root.data)
  }

> 前中后序均指相对于根来说.
> 每个节点最多会被访问两次， 所以遍历操作的时间复杂度， 跟节点的个数 n 成正比， 也就是说二叉树遍历的时间复杂度是 O(n).

#### 递推公式
前序遍历的递推公式：preOrder(r) = print r->preOrder(r->left)->preOrder(r->right)
中序遍历的递推公式：postOrder(r) = postOrder(r->left)->print r->postOrder(r->right)
后序遍历的递推公式：postOrder(r) = postOrder(r->left)->postOrder(r->right)->print r

### 二叉查找树/二叉搜索树(binary search tree)
二叉查找树要求， 在树中的任意一个节点， 其左子树中的每个节点的值， 都要小于这个节点的值， 而右子树节点的值都大于这个节点的值.

最大的特点就是， 支持动态数据集合的快速插入、 删除、 查找操作, 且时间复杂度也比较稳定， 是 O(logn).

### 红黑树
二叉查找树在频繁的动态更新过程中，可能会出现树的高度远大于 logN 的情况，从而导致各个操作的效率下降.极端情况下，二叉树会退化为链表，时间复杂度会退化到 O(n). 要解决这个复杂度退化的问题，需要设计一种平衡二叉查找树，也就是红黑树.

> 平衡二叉树的严格定义是这样的：二叉树中任意一个节点的左右子树的高度相差不能大于 1. 从这个定义来看，上一节我们讲的完全二叉树、满二叉树其实都是平衡二叉树，但是非完全二叉树也有可能是平衡二叉树.
> 平衡二叉查找树其实有很多，比如，Splay Tree（伸展树）、Treap（树堆）等，但是我们提到平衡二叉查找树，听到的基本都是红黑树, 为什么它们不是: 绝大部分情况下，它们操作的效率都很高，但是也无法避免极端情况下时间复杂度的退化.
> 红黑树是“近似平衡”的: 平衡二叉查找树的初衷，是为了解决二叉查找树因为动态更新导致的性能退化问题。所以，“平衡”的意思可以等价为性能不退化。“近似平衡”就等价为性能不会退化的太严重

红黑树中的节点，一类被标记为黑色，一类被标记为红色。除此之外，一棵红黑树还需要满足这样几个要求：
1. 根节点是黑色的
1. 每个叶子节点都是黑色的空节点，也就是说，叶子节点不存储数据
1. 任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的
1. 每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点

### 堆
堆是一种特殊的树

### trie树
trie树即字典树, 又称为单词查找树或键树, 是一种哈希树的变种.

trie树的核心思想是空间换时间. 利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的.

典型应用是用于统计和排序大量的字符串(但不仅限于字符串), 通常用于搜索引擎的文本字频统计.

优点: 最大限度地减少无谓的字符串比较, 查询效率比hash高

### 并查集
并查集(union & find)是一种树型的数据结构, 用于处理一些不交集(disjoint set)的合并及查询问题.

union: 将两个子集合并成同一个集合.
find: 确定元素属于哪个子集合, 它可以被用来确定两个元素是否属于同一子集.

实现: 通常是数组
典型场景: 帮派/组织识别

优化:
1. union时将深度(rank)小的树合并到深度大的树, 便于限制合并后的树的深度.
1. find时的路径压缩(所有节点直接指向根)

### Btree/B+tree
ref:
- [B+树原理以及Go语言实现](https://segmentfault.com/a/1190000041696709)

B-tree即B树.

阶数 表示 此B树的节点（除根节点外） **最多有多少个孩子结点（子树）**，一般用字母 M 表示阶数.

B树又称多路平衡查找树，B树中所有结点的孩子个数的最大值称为B树的阶，通常用M表示. 一般从查找效率考虑，通常要求M>=3. 一棵M阶B树，有如下特性：
1. 若根节点不是叶子结点，则至少有两棵树
1. 每一个节点最多M棵子树，最多有M-1个关键字。
1. 除根节点外，其他的每个分支至少有ceil(M/2)个子树，至少含有ceil(M/2)-1个关键字
1. 每个节点中的关键字都按照大小顺序排列，每个关键字的左子树的所有关键字都小于它，每个关键字的右子树都大于它
1. 所有叶子节点都位于同一层，或者说根节点到每个叶子节点的长度都相同


为了适应磁盘IO访问的特点以及适应范围查询的需求，B+树对B树进行了改进. 对于一棵m阶的B+树，有如下特性：

1. 每个节点**至多**有M个子树
1. 除根结点外，每个结点**至少**有ceil(M/2)个子树
1. 结点的子树个数与关键字个数相等
1. 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接
1. 所有的非终端结点（非叶子结点）可以看成是索引部分，结点中仅含有其子树（根结点）中的最大（或最小）关键字

B+树和B树相比，主要有以下区别：
1. 非叶子节点只存储键值信息，数据记录都存放在叶子节点中
1. 所有叶子节点之间都有一个链指针
1. 非叶子节点的关键字的个数与其子树的个数相同，不像B树，子树的个数总比关键字个数多1个

B+tree有两种定义 from [B+树原理以及Java代码实现](https://blog.csdn.net/u014106644/article/details/90174332):
1. 阶的B树中，有M-1个关键字数 和 M-1个子结点: 关键字个数和孩子结点个数相同

  每个元素是子结点元素里的最大值或最小值
2. M阶的B树中，有M-1个关键字数 和 M个子结点: 关键字个数比孩子结点个数小1，这种方式是和B树基本等价的.

  最左边的子结点小于最小的元素，其余的子结点是>=当前元素

B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针

`B*树的分裂`：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针；`B*树`分配新结点的概率比B+树要低，空间使用率更高

`B+-tree`: 在`B+tree`叶子结点间的指针是双向指针.

`B*树是B+树的变体`: 在B+树的非根和非叶子节点增加了指向兄弟的指针.

## FAQ
1. 散列表的插入、 删除、 查找操作的时间复杂度可以做到常量级的 O(1)非常高效, 而二叉查找树在比较平衡的情况下， 插入、 删除、 查找操作时间复杂度才是 O(logn)， 相对散列表， 好像并没有什么优势， 那我们为什么还要用二叉查找树呢？
  1. 散列表中的数据是无序存储的， 如果要输出有序的数据， 需要先进行排序;而对于二叉查找树来说， 我们只需要中序遍历， 就可以在 O(n) 的时间复杂度内， 输出有序的数据序列.
  1. 散列表扩容耗时很多， 而且当遇到散列冲突时， 性能不稳定， 尽管二叉查找树的性能不稳定， 但是在工程中， 我们最常用的平衡二叉查找树的性能非常稳定， 时间复杂度稳定在 O(logn)
  1. 尽管散列表的查找等操作的时间复杂度是常量级的， 但因为哈希冲突的存在，这个常量不一定比 logn 小， 所以实际的查找速度可能不一定比 O(logn) 快。 加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高
  1. 散列表的构造比二叉查找树要复杂， 需要考虑的东西很多。 比如散列函数的设计、 冲突解决办法、 扩容、 缩容等。 平衡二叉查找树只需要考虑平衡性这一个问题， 而且这个问题的解决方案比较成熟、 固定
  1. 为了避免过多的散列冲突， 散列表装载因子不能太大， 特别是基于开放寻址法解决冲突的散列表， 不然会浪费一定的存储空间
